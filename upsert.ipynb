{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23907c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing all existing vectors from Pinecone index...\n",
      "All vectors cleared. Starting fresh.\n"
     ]
    }
   ],
   "source": [
    "from pinecone import Pinecone\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "pc_api_key = os.environ.get(\"PINECONE_API_KEY\")\n",
    "pc = Pinecone(api_key=pc_api_key)\n",
    "pc_index_url = os.environ.get(\"PINECONE_INDEX_URL\")\n",
    "pc_index_name = \"openclio\"\n",
    "pc_index = pc.Index(name=pc_index_name, host=pc_index_url) # Initializing the Pinecone index with host.\n",
    "\n",
    "pc.describe_index(\"openclio\") # Describing the Pinecone index, to ensure that it was loaded in correctly.\n",
    "\n",
    "# Clear all existing vectors from the index to start fresh\n",
    "\n",
    "print(\"Clearing all existing vectors from Pinecone index...\")\n",
    "pc_index.delete(delete_all=True)\n",
    "print(\"All vectors cleared. Starting fresh.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29341fcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model                               0\n",
      "Conversation                        0\n",
      "Language                            0\n",
      "Toxic                               0\n",
      "State                               0\n",
      "Country                             0\n",
      "Hour of Day                         0\n",
      "Topic_Embedding                     0\n",
      "Topic                               0\n",
      "L0_cluster_id                       0\n",
      "L0_cluster_label                    0\n",
      "L0_cluster_description              0\n",
      "L0_cluster_description_embedding    0\n",
      "L1_cluster_id                       0\n",
      "L1_cluster_label                    0\n",
      "L1_cluster_description              0\n",
      "L1_cluster_description_embedding    0\n",
      "L2_cluster_id                       0\n",
      "L2_cluster_label                    0\n",
      "L2_cluster_description              0\n",
      "L2_cluster_description_embedding    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load in the CSV `selected_conversations_with_topics_embedded_clustered.csv` as a dataframe.\n",
    "df = pd.read_csv(\"selected_conversations_with_topics_embedded_clustered.csv\")\n",
    "\n",
    "# Pre-processing the entire df to replace all NaNs with empty strings.\n",
    "df = df.fillna(\"\")\n",
    "\n",
    "# Write a basic test/log to ensure that no NaNs are present in the df.\n",
    "print(df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ded814c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   L2_cluster_id                         L2_cluster_label  \\\n",
      "0              0  Technical Problem-Solving Methodologies   \n",
      "1              1          Fictional Narrative Exploration   \n",
      "2              2                    AI Capability Testing   \n",
      "3              3     Technical Problem-Solving Assistance   \n",
      "4              4              Vocal Technique Comparisons   \n",
      "\n",
      "                              L2_cluster_description  \\\n",
      "0  This cluster represents systematic approaches ...   \n",
      "1  This cluster represents user-generated content...   \n",
      "2  This cluster represents comprehensive user int...   \n",
      "3  This cluster represents a comprehensive collec...   \n",
      "4  This cluster encompasses user inquiries that s...   \n",
      "\n",
      "                    L2_cluster_description_embedding  L2_cluster_trace_count  \n",
      "0  [-0.00941457785665989, -0.0065292189829051495,...                      54  \n",
      "1  [-0.01923833228647709, 0.01746535860002041, -0...                     193  \n",
      "2  [-0.00421322463080287, 0.01365547627210617, -0...                     537  \n",
      "3  [0.00796633493155241, 0.005814108066260815, -0...                     209  \n",
      "4  [-0.011478818021714687, -0.0010936849284917116...                       7  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upserting L2 clusters: 100%|██████████| 5/5 [00:01<00:00,  4.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully upserted L2 clusters.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## Processing L2 clusters (highest-level clusters extracted from the trace data). \n",
    "import ast\n",
    "from tqdm import tqdm\n",
    "\n",
    "# First, calculate trace counts for each L2 cluster\n",
    "unique_l2_clusters = (\n",
    "    df.groupby([\"L2_cluster_id\", \"L2_cluster_label\", \"L2_cluster_description\", \"L2_cluster_description_embedding\"])\n",
    "    .size()\n",
    "    .reset_index(name=\"L2_cluster_trace_count\")\n",
    ")\n",
    "\n",
    "# Printing the first few unique clusters.\n",
    "print(unique_l2_clusters.head())\n",
    "\n",
    "# Initializing L2 cluster metadata before upserting.\n",
    "for idx, row in tqdm(unique_l2_clusters.iterrows(), total=len(unique_l2_clusters), desc=\"Upserting L2 clusters\"):\n",
    "    l2_cluster_metadata = {\n",
    "        \"type\": \"l2_cluster\",\n",
    "        \"name\": row[\"L2_cluster_label\"],\n",
    "        \"description\": row[\"L2_cluster_description\"],\n",
    "        \"trace_count\": row[\"L2_cluster_trace_count\"],\n",
    "    }\n",
    "    values = ast.literal_eval(row[\"L2_cluster_description_embedding\"])\n",
    "    vectors = [{\n",
    "        \"id\": f\"l2_cluster_{idx}\",\n",
    "        \"values\": values,\n",
    "        \"metadata\": l2_cluster_metadata,\n",
    "    }]\n",
    "    upsert_response = pc_index.upsert(vectors=vectors)\n",
    "    assert upsert_response[\"upserted_count\"] == 1 # Ensure that the upsert was successful.\n",
    "\n",
    "print(\"Successfully upserted L2 clusters.\") # If we've reached this point, then the L2 clusters have been upserted successfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7a85591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   L1_cluster_id                          L1_cluster_label  \\\n",
      "0              0  Methodological and Analytical Frameworks   \n",
      "1              1             AI Assistant Boundary Testing   \n",
      "2              2                   Broad Knowledge Testing   \n",
      "3              3              TrueNAS Storage Optimization   \n",
      "4              4     Game of Thrones speculative scenarios   \n",
      "\n",
      "                              L1_cluster_description  \\\n",
      "0  This cluster encompasses discussions centered ...   \n",
      "1  This cluster represents diverse user interacti...   \n",
      "2  This cluster represents user interactions that...   \n",
      "3  This cluster encompasses comprehensive discuss...   \n",
      "4  This cluster encompasses user-generated conten...   \n",
      "\n",
      "                    L1_cluster_description_embedding  L2_cluster_id  \\\n",
      "0  [-0.0216191615909338, 0.013525794260203838, -0...              0   \n",
      "1  [-0.008321586064994335, -0.0033742745872586966...              2   \n",
      "2  [-0.0021743522956967354, 0.019716961309313774,...              2   \n",
      "3  [-0.006666019558906555, 0.000851398624945432, ...              0   \n",
      "4  [-0.013002265244722366, 0.0060457391664385796,...              1   \n",
      "\n",
      "   L1_cluster_trace_count  \n",
      "0                      15  \n",
      "1                     134  \n",
      "2                     146  \n",
      "3                      16  \n",
      "4                      18  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upserting L1 clusters:   0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upsert response: {'upserted_count': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upserting L1 clusters:   8%|▊         | 2/25 [00:00<00:02,  8.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upsert response: {'upserted_count': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upserting L1 clusters:  16%|█▌        | 4/25 [00:00<00:01, 10.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upsert response: {'upserted_count': 1}\n",
      "Upsert response: {'upserted_count': 1}\n",
      "Upsert response: {'upserted_count': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upserting L1 clusters:  24%|██▍       | 6/25 [00:00<00:01, 11.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upsert response: {'upserted_count': 1}\n",
      "Upsert response: {'upserted_count': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upserting L1 clusters:  32%|███▏      | 8/25 [00:00<00:01, 11.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upsert response: {'upserted_count': 1}\n",
      "Upsert response: {'upserted_count': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upserting L1 clusters:  40%|████      | 10/25 [00:00<00:01, 11.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upsert response: {'upserted_count': 1}\n",
      "Upsert response: {'upserted_count': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upserting L1 clusters:  48%|████▊     | 12/25 [00:01<00:01, 10.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upsert response: {'upserted_count': 1}\n",
      "Upsert response: {'upserted_count': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upserting L1 clusters:  56%|█████▌    | 14/25 [00:01<00:01, 10.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upsert response: {'upserted_count': 1}\n",
      "Upsert response: {'upserted_count': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upserting L1 clusters:  64%|██████▍   | 16/25 [00:01<00:00, 10.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upsert response: {'upserted_count': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upserting L1 clusters:  72%|███████▏  | 18/25 [00:01<00:00, 10.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upsert response: {'upserted_count': 1}\n",
      "Upsert response: {'upserted_count': 1}\n",
      "Upsert response: {'upserted_count': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upserting L1 clusters:  80%|████████  | 20/25 [00:01<00:00, 10.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upsert response: {'upserted_count': 1}\n",
      "Upsert response: {'upserted_count': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upserting L1 clusters:  88%|████████▊ | 22/25 [00:02<00:00, 11.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upsert response: {'upserted_count': 1}\n",
      "Upsert response: {'upserted_count': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upserting L1 clusters: 100%|██████████| 25/25 [00:02<00:00, 10.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upsert response: {'upserted_count': 1}\n",
      "Upsert response: {'upserted_count': 1}\n",
      "Successfully upserted L1 clusters.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Next, we need to upsert the L1 clusters (lower-level clusters than L2, but still pretty high).\n",
    "from tqdm import tqdm\n",
    "\n",
    "unique_l1_clusters = (\n",
    "    df.groupby([\"L1_cluster_id\", \"L1_cluster_label\", \"L1_cluster_description\", \"L1_cluster_description_embedding\", \"L2_cluster_id\"])\n",
    "    .size()\n",
    "    .reset_index(name=\"L1_cluster_trace_count\")\n",
    ")\n",
    "print(unique_l1_clusters.head())\n",
    "\n",
    "for idx, row in tqdm(unique_l1_clusters.iterrows(), total=len(unique_l1_clusters), desc=\"Upserting L1 clusters\"):\n",
    "    l1_cluster_metadata = {\n",
    "        \"type\": \"l1_cluster\",\n",
    "        \"L2_cluster_id\": row[\"L2_cluster_id\"], # Need to store the L2 cluster ID for the L1 cluster, so that this can be returned in tool calls later on.\n",
    "        \"name\": row[\"L1_cluster_label\"],\n",
    "        \"description\": row[\"L1_cluster_description\"],\n",
    "        \"trace_count\": row[\"L1_cluster_trace_count\"],\n",
    "    }\n",
    "    values = ast.literal_eval(row[\"L1_cluster_description_embedding\"])\n",
    "    vectors = [{\n",
    "        \"id\": f\"l1_cluster_{idx}\",\n",
    "        \"values\": values,\n",
    "        \"metadata\": l1_cluster_metadata,\n",
    "    }]\n",
    "    upsert_response = pc_index.upsert(vectors=vectors)\n",
    "    print(f\"Upsert response: {upsert_response}\")\n",
    "    assert upsert_response[\"upserted_count\"] == 1 # Ensure that the upsert was successful.\n",
    "\n",
    "print(\"Successfully upserted L1 clusters.\") # If we've reached this point, then the L1 clusters have been upserted successfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1dcf8d31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   L0_cluster_id              L0_cluster_label  \\\n",
      "0              0  Programming Error Resolution   \n",
      "1              1     AI Assistant Interactions   \n",
      "2              2  Fictional Character Reunions   \n",
      "3              3  Diverse Information Requests   \n",
      "4              4  Diverse Information Requests   \n",
      "\n",
      "                              L0_cluster_description  \\\n",
      "0  This cluster represents a collection of progra...   \n",
      "1  This cluster represents diverse user interacti...   \n",
      "2  This cluster represents requests for creative ...   \n",
      "3  This cluster represents a wide range of user q...   \n",
      "4  This cluster represents a wide range of user q...   \n",
      "\n",
      "                    L0_cluster_description_embedding  L1_cluster_id  \\\n",
      "0  [-0.001186206005513668, 0.008096595294773579, ...             10   \n",
      "1  [-0.0019425011705607176, 0.006542277056723833,...              1   \n",
      "2  [-0.02054133079946041, 0.017430299893021584, -...              8   \n",
      "3  [-0.0035605276934802532, 0.011465399526059628,...              2   \n",
      "4  [0.00218771630898118, 0.020166805014014244, -0...              2   \n",
      "\n",
      "   L2_cluster_id  L0_cluster_trace_count  \n",
      "0              3                      25  \n",
      "1              2                      54  \n",
      "2              1                       9  \n",
      "3              2                      33  \n",
      "4              2                      44  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upserting L0 clusters:   4%|▍         | 2/50 [00:00<00:04, 10.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upsert response: {'upserted_count': 1}\n",
      "Upsert response: {'upserted_count': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upserting L0 clusters:   8%|▊         | 4/50 [00:00<00:07,  6.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upsert response: {'upserted_count': 1}\n",
      "Upsert response: {'upserted_count': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upserting L0 clusters:  12%|█▏        | 6/50 [00:00<00:06,  6.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upsert response: {'upserted_count': 1}\n",
      "Upsert response: {'upserted_count': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upserting L0 clusters:  16%|█▌        | 8/50 [00:01<00:06,  6.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upsert response: {'upserted_count': 1}\n",
      "Upsert response: {'upserted_count': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upserting L0 clusters:  20%|██        | 10/50 [00:01<00:05,  7.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upsert response: {'upserted_count': 1}\n",
      "Upsert response: {'upserted_count': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upserting L0 clusters:  24%|██▍       | 12/50 [00:01<00:04,  8.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upsert response: {'upserted_count': 1}\n",
      "Upsert response: {'upserted_count': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upserting L0 clusters:  28%|██▊       | 14/50 [00:01<00:03,  9.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upsert response: {'upserted_count': 1}\n",
      "Upsert response: {'upserted_count': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upserting L0 clusters:  32%|███▏      | 16/50 [00:01<00:03,  9.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upsert response: {'upserted_count': 1}\n",
      "Upsert response: {'upserted_count': 1}\n",
      "Upsert response: {'upserted_count': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upserting L0 clusters:  36%|███▌      | 18/50 [00:02<00:03,  8.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upsert response: {'upserted_count': 1}\n",
      "Upsert response: {'upserted_count': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upserting L0 clusters:  42%|████▏     | 21/50 [00:02<00:03,  7.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upsert response: {'upserted_count': 1}\n",
      "Upsert response: {'upserted_count': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upserting L0 clusters:  46%|████▌     | 23/50 [00:02<00:03,  7.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upsert response: {'upserted_count': 1}\n",
      "Upsert response: {'upserted_count': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upserting L0 clusters:  50%|█████     | 25/50 [00:03<00:03,  8.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upsert response: {'upserted_count': 1}\n",
      "Upsert response: {'upserted_count': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upserting L0 clusters:  54%|█████▍    | 27/50 [00:03<00:02,  8.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upsert response: {'upserted_count': 1}\n",
      "Upsert response: {'upserted_count': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upserting L0 clusters:  58%|█████▊    | 29/50 [00:03<00:02,  8.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upsert response: {'upserted_count': 1}\n",
      "Upsert response: {'upserted_count': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upserting L0 clusters:  62%|██████▏   | 31/50 [00:03<00:02,  8.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upsert response: {'upserted_count': 1}\n",
      "Upsert response: {'upserted_count': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upserting L0 clusters:  66%|██████▌   | 33/50 [00:04<00:02,  8.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upsert response: {'upserted_count': 1}\n",
      "Upsert response: {'upserted_count': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upserting L0 clusters:  70%|███████   | 35/50 [00:04<00:01,  8.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upsert response: {'upserted_count': 1}\n",
      "Upsert response: {'upserted_count': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upserting L0 clusters:  76%|███████▌  | 38/50 [00:04<00:01,  9.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upsert response: {'upserted_count': 1}\n",
      "Upsert response: {'upserted_count': 1}\n",
      "Upsert response: {'upserted_count': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upserting L0 clusters:  80%|████████  | 40/50 [00:04<00:00, 10.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upsert response: {'upserted_count': 1}\n",
      "Upsert response: {'upserted_count': 1}\n",
      "Upsert response: {'upserted_count': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upserting L0 clusters:  86%|████████▌ | 43/50 [00:05<00:00,  8.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upsert response: {'upserted_count': 1}\n",
      "Upsert response: {'upserted_count': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upserting L0 clusters:  90%|█████████ | 45/50 [00:05<00:00,  9.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upsert response: {'upserted_count': 1}\n",
      "Upsert response: {'upserted_count': 1}\n",
      "Upsert response: {'upserted_count': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upserting L0 clusters:  98%|█████████▊| 49/50 [00:05<00:00, 10.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upsert response: {'upserted_count': 1}\n",
      "Upsert response: {'upserted_count': 1}\n",
      "Upsert response: {'upserted_count': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upserting L0 clusters: 100%|██████████| 50/50 [00:05<00:00,  8.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upsert response: {'upserted_count': 1}\n",
      "Successfully upserted L0 clusters.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Next, we need to upsert the L0 clusters (lowest-level clusters, which are a level above the topics/trace descriptions).\n",
    "from tqdm import tqdm\n",
    "\n",
    "unique_l0_clusters = (\n",
    "    df.groupby([\"L0_cluster_id\", \"L0_cluster_label\", \"L0_cluster_description\", \"L0_cluster_description_embedding\", \"L1_cluster_id\", \"L2_cluster_id\"])\n",
    "    .size()\n",
    "    .reset_index(name=\"L0_cluster_trace_count\")\n",
    ")\n",
    "print(unique_l0_clusters.head())\n",
    "\n",
    "for idx, row in tqdm(unique_l0_clusters.iterrows(), total=len(unique_l0_clusters), desc=\"Upserting L0 clusters\"):\n",
    "    l0_cluster_metadata = {\n",
    "        \"type\": \"l0_cluster\",\n",
    "        \"L1_cluster_id\": row[\"L1_cluster_id\"], # Need to store the L1 cluster ID for the L0 cluster, so that this can be returned in tool calls later on.\n",
    "        \"L2_cluster_id\": row[\"L2_cluster_id\"], # Need to store the L2 cluster ID for the L0 cluster, so that this can be returned in tool calls later on.\n",
    "        \"name\": row[\"L0_cluster_label\"],\n",
    "        \"description\": row[\"L0_cluster_description\"],\n",
    "        \"trace_count\": row[\"L0_cluster_trace_count\"],\n",
    "    }\n",
    "    values = ast.literal_eval(row[\"L0_cluster_description_embedding\"])\n",
    "    vectors = [{\n",
    "        \"id\": f\"l0_cluster_{idx}\",\n",
    "        \"values\": values,\n",
    "        \"metadata\": l0_cluster_metadata,\n",
    "    }]\n",
    "    upsert_response = pc_index.upsert(vectors=vectors) \n",
    "    print(f\"Upsert response: {upsert_response}\")\n",
    "    assert upsert_response[\"upserted_count\"] == 1 # Ensure that the upsert was successful.\n",
    "\n",
    "print(\"Successfully upserted L0 clusters.\") # If we've reached this point, then the L0 clusters have been upserted successfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0eda5d8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Topic\n",
      "0  The user requested a personalized reality-shif...\n",
      "1  The user asked about the highest risk factor f...\n",
      "2  The user asked for a personalized reality-shif...\n",
      "3  The user asked for help choosing a reality-shi...\n",
      "4  The user asked the assistant to write terms an...\n",
      "995\n"
     ]
    }
   ],
   "source": [
    "unique_topics = df.drop_duplicates(subset=[\"Topic\"]).reset_index(drop=True)\n",
    "print(unique_topics[[\"Topic\"]].head())\n",
    "print(len(unique_topics[\"Topic\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "224006fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upserting topics: 100%|██████████| 995/995 [00:00<00:00, 7813.24it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extracting chunk description\n",
    "import ast\n",
    "all_messages = []   \n",
    "for i, row in tqdm(\n",
    "    unique_topics.iterrows(), total=len(unique_topics), desc=\"Upserting topics\"\n",
    "):\n",
    "\n",
    "    # Remove 'defaultdict' wrapper if present and safely convert to dict\n",
    "    raw_description = row[\"Conversation\"]\n",
    "    # For each conversation, extract the messages as a flat list: user, assistant, user, assistant, ...\n",
    "    # Handle the defaultdict(<class ...>, {...}) wrapper if present\n",
    "\n",
    "    messages = []\n",
    "\n",
    "    if isinstance(raw_description, str) and raw_description.startswith(\"defaultdict\"):\n",
    "        # Removes 'defaultdict(<class ...>, {...})' wrapper\n",
    "        start = raw_description.find(\"{\")\n",
    "        end = raw_description.rfind(\"}\")\n",
    "        if start != -1 and end != -1:\n",
    "            dict_str = raw_description[start:end+1]\n",
    "            try:\n",
    "                conversation_dict = ast.literal_eval(dict_str)\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to parse dict from defaultdict string: {e}\")\n",
    "                conversation_dict = {}\n",
    "        else:\n",
    "            conversation_dict = {}\n",
    "    # If not a defaultdict wrapper, try to eval string or use as-is\n",
    "    elif isinstance(raw_description, str):\n",
    "        try:\n",
    "            conversation_dict = ast.literal_eval(raw_description)\n",
    "        except Exception:\n",
    "            conversation_dict = {}\n",
    "    elif isinstance(raw_description, dict):\n",
    "        conversation_dict = raw_description\n",
    "    else:\n",
    "        conversation_dict = {}\n",
    "\n",
    "    # Now extract the turns as messages in order.\n",
    "    # conversation_dict should be a mapping of turn_number -> {'user': ..., 'assistant': ...}\n",
    "    if isinstance(conversation_dict, dict):\n",
    "        for turn_id in sorted(conversation_dict.keys()):\n",
    "            turn = conversation_dict[turn_id]\n",
    "            if isinstance(turn, dict):\n",
    "                if \"user\" in turn:\n",
    "                    messages.append(turn[\"user\"])\n",
    "                if \"assistant\" in turn:\n",
    "                    messages.append(turn[\"assistant\"])\n",
    "\n",
    "    #print(messages)\n",
    "    all_messages.append(messages)\n",
    "\n",
    "\n",
    "len(all_messages[182])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "279222a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upserting topics: 100%|██████████| 995/995 [00:00<00:00, 8467.43it/s]\n"
     ]
    }
   ],
   "source": [
    "# Extracting chunk description\n",
    "import ast\n",
    "\n",
    "for i, row in tqdm(unique_topics.iterrows(), total=len(unique_topics), desc=\"Upserting topics\"):\n",
    "\n",
    "    # Remove 'defaultdict' wrapper if present and safely convert to dict\n",
    "    raw_description = row[\"Conversation\"]\n",
    "    if isinstance(raw_description, str) and raw_description.startswith(\"defaultdict\"):\n",
    "        # Removes 'defaultdict(<class ...>, {...})' wrapper\n",
    "        start = raw_description.find(\"{\")\n",
    "        end = raw_description.rfind(\"}\")\n",
    "        if start != -1 and end != -1:\n",
    "            dict_str = raw_description[start:end+1]\n",
    "            try:\n",
    "                description = ast.literal_eval(dict_str)\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to parse dict from defaultdict string: {e}\")\n",
    "                description = dict_str  # fallback to raw string if parsing fails\n",
    "        else:\n",
    "            description = raw_description\n",
    "    else:\n",
    "        description = raw_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "020c493a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upserting topics: 100%|██████████| 995/995 [01:53<00:00,  8.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully upserted topics.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Helper function to calculate metadata size in bytes\n",
    "def calculate_metadata_size(metadata):\n",
    "    \"\"\"Calculate the size of metadata when serialized to JSON.\"\"\"\n",
    "    return len(json.dumps(metadata).encode('utf-8'))\n",
    "\n",
    "# Helper function to chunk trace messages to fit within size limit\n",
    "def chunk_trace_messages(trace_messages, max_size_bytes, base_metadata_without_trace, description):\n",
    "    \"\"\"\n",
    "    Split trace_messages into chunks that fit within the size limit.\n",
    "    Returns a list of trace chunks, each as a list of messages.\n",
    "    \"\"\"\n",
    "    # Helper to create complete metadata for size testing\n",
    "    def create_test_metadata(trace_chunk, total_chunks, chunk_idx):\n",
    "        \"\"\"Create complete metadata for size calculation.\"\"\"\n",
    "        metadata = base_metadata_without_trace.copy()\n",
    "        metadata[\"description\"] = description\n",
    "        metadata[\"trace\"] = trace_chunk\n",
    "        metadata[\"total_trace_chunks\"] = total_chunks\n",
    "        metadata[\"trace_chunk_idx\"] = chunk_idx\n",
    "        return metadata\n",
    "    \n",
    "    # Estimate total chunks (we'll refine this, but use conservative estimate)\n",
    "    # Start by checking if full trace fits with single chunk\n",
    "    test_metadata = create_test_metadata(trace_messages, 1, 0)\n",
    "    full_trace_size = calculate_metadata_size(test_metadata)\n",
    "    \n",
    "    safety_buffer = 1000  # extra buffer for JSON encoding variations and future total_chunks changes\n",
    "    \n",
    "    if full_trace_size <= max_size_bytes - safety_buffer:\n",
    "        return [trace_messages]  # Full trace fits, return as single chunk\n",
    "    \n",
    "    # Need to chunk the trace\n",
    "    # We'll estimate total chunks conservatively - assume we might need many chunks\n",
    "    # Use a reasonable estimate: assume average chunk size based on first few messages\n",
    "    estimated_total_chunks = max(2, len(trace_messages) // 10)  # rough estimate\n",
    "    \n",
    "    trace_chunks = []\n",
    "    current_chunk = []\n",
    "    \n",
    "    for message in trace_messages:\n",
    "        # Test adding this message to current chunk\n",
    "        test_chunk = current_chunk + [message]\n",
    "        # Use current chunk index for testing\n",
    "        test_metadata = create_test_metadata(test_chunk, estimated_total_chunks, len(trace_chunks))\n",
    "        test_size = calculate_metadata_size(test_metadata)\n",
    "        \n",
    "        if test_size <= max_size_bytes - safety_buffer:\n",
    "            # Message fits, add to current chunk\n",
    "            current_chunk = test_chunk\n",
    "        else:\n",
    "            # Message doesn't fit, save current chunk and start new one\n",
    "            if current_chunk:\n",
    "                trace_chunks.append(current_chunk)\n",
    "            current_chunk = [message]\n",
    "    \n",
    "    # Add final chunk\n",
    "    if current_chunk:\n",
    "        trace_chunks.append(current_chunk)\n",
    "    \n",
    "    # Final verification: recalculate with actual total_chunks\n",
    "    actual_total_chunks = len(trace_chunks)\n",
    "    final_chunks = []\n",
    "    for idx, chunk in enumerate(trace_chunks):\n",
    "        verify_metadata = create_test_metadata(chunk, actual_total_chunks, idx)\n",
    "        verify_size = calculate_metadata_size(verify_metadata)\n",
    "        if verify_size > max_size_bytes:\n",
    "            # This shouldn't happen, but if it does, we need to split further\n",
    "            print(f\"Warning: Chunk {idx} still exceeds limit ({verify_size} bytes), splitting further...\")\n",
    "            # Split this chunk in half (simple fallback)\n",
    "            mid = len(chunk) // 2\n",
    "            if mid > 0:\n",
    "                final_chunks.append(chunk[:mid])\n",
    "                final_chunks.append(chunk[mid:])\n",
    "            else:\n",
    "                final_chunks.append(chunk)\n",
    "        else:\n",
    "            final_chunks.append(chunk)\n",
    "    \n",
    "    return final_chunks if final_chunks else [trace_messages]\n",
    "\n",
    "# Actually upsert to Pinecone with the trace as a list of strings\n",
    "PINECONE_METADATA_LIMIT = 40960  # 40KB limit\n",
    "\n",
    "for i, row in tqdm(unique_topics.iterrows(), total=len(unique_topics), desc=\"Upserting topics\"):\n",
    "    # Get the trace as produced above\n",
    "    trace_messages = all_messages[i]\n",
    "\n",
    "    # Base metadata without trace (we'll add trace chunks separately)\n",
    "    base_metadata_without_trace = {\n",
    "        \"type\": \"topic\",\n",
    "        \"L0_cluster_id\": row[\"L0_cluster_id\"],\n",
    "        \"L1_cluster_id\": row[\"L1_cluster_id\"],\n",
    "        \"L2_cluster_id\": row[\"L2_cluster_id\"],\n",
    "        \"model\": row[\"Model\"],\n",
    "        \"toxic\": row[\"Toxic\"],\n",
    "        \"state\": row[\"State\"],\n",
    "        \"country\": row[\"Country\"],\n",
    "        \"hour\": row[\"Hour of Day\"],\n",
    "    }\n",
    "    \n",
    "    description = row[\"Topic\"]\n",
    "    values = ast.literal_eval(row[\"Topic_Embedding\"])\n",
    "    \n",
    "    # Chunk trace messages if necessary\n",
    "    trace_chunks = chunk_trace_messages(\n",
    "        trace_messages, \n",
    "        PINECONE_METADATA_LIMIT, \n",
    "        base_metadata_without_trace,\n",
    "        description\n",
    "    )\n",
    "    \n",
    "    total_trace_chunks = len(trace_chunks)\n",
    "    \n",
    "    # Create a vector for each trace chunk\n",
    "    for trace_chunk_idx, trace_chunk in enumerate(trace_chunks):\n",
    "        chunk_metadata = base_metadata_without_trace.copy()\n",
    "        chunk_metadata[\"description\"] = description\n",
    "        chunk_metadata[\"trace\"] = trace_chunk        \n",
    "        # Use trace_chunk_idx as the chunk_idx in the vector ID\n",
    "        vector_id = f\"topic_{i}_{trace_chunk_idx}\"\n",
    "        \n",
    "        vectors = [{\n",
    "            \"id\": vector_id,\n",
    "            \"values\": values,\n",
    "            \"metadata\": chunk_metadata,\n",
    "        }]\n",
    "        \n",
    "        # Verify the metadata size before upserting\n",
    "        metadata_size = calculate_metadata_size(chunk_metadata)\n",
    "        if metadata_size > PINECONE_METADATA_LIMIT:\n",
    "            print(f\"Warning: Vector {vector_id} metadata size ({metadata_size} bytes) exceeds limit!\")\n",
    "        \n",
    "        upsert_response = pc_index.upsert(vectors=vectors)\n",
    "        assert upsert_response[\"upserted_count\"] == 1\n",
    "\n",
    "print(\"Successfully upserted topics.\") # If we've reached this point, then the topics have been upserted successfully."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
