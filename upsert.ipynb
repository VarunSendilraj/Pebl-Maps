{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23907c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vkodithala/miniconda3/envs/env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing all existing vectors from Pinecone index...\n",
      "All vectors cleared. Starting fresh.\n"
     ]
    }
   ],
   "source": [
    "from pinecone import Pinecone\n",
    "import os\n",
    "\n",
    "pc_api_key = os.environ.get(\"PINECONE_API_KEY\")\n",
    "pc = Pinecone(api_key=pc_api_key)\n",
    "pc_index_url = os.environ.get(\"PINECONE_INDEX_URL\")\n",
    "pc_index_name = \"openclio\"\n",
    "pc_index = pc.Index(name=pc_index_name, host=pc_index_url) # Initializing the Pinecone index with host.\n",
    "\n",
    "pc.describe_index(\"openclio\") # Describing the Pinecone index, to ensure that it was loaded in correctly.\n",
    "\n",
    "# Clear all existing vectors from the index to start fresh\n",
    "\n",
    "print(\"Clearing all existing vectors from Pinecone index...\")\n",
    "pc_index.delete(delete_all=True)\n",
    "print(\"All vectors cleared. Starting fresh.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29341fcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model                               0\n",
      "Conversation                        0\n",
      "Language                            0\n",
      "Toxic                               0\n",
      "State                               0\n",
      "Country                             0\n",
      "Hour of Day                         0\n",
      "Topic_Embedding                     0\n",
      "Topic                               0\n",
      "L0_cluster_id                       0\n",
      "L0_cluster_label                    0\n",
      "L0_cluster_description              0\n",
      "L0_cluster_description_embedding    0\n",
      "L1_cluster_id                       0\n",
      "L1_cluster_label                    0\n",
      "L1_cluster_description              0\n",
      "L1_cluster_description_embedding    0\n",
      "L2_cluster_id                       0\n",
      "L2_cluster_label                    0\n",
      "L2_cluster_description              0\n",
      "L2_cluster_description_embedding    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load in the CSV `selected_conversations_with_topics_embedded_clustered.csv` as a dataframe.\n",
    "df = pd.read_csv(\"selected_conversations_with_topics_embedded_clustered.csv\")\n",
    "\n",
    "# Pre-processing the entire df to replace all NaNs with empty strings.\n",
    "df = df.fillna(\"\")\n",
    "\n",
    "# Write a basic test/log to ensure that no NaNs are present in the df.\n",
    "print(df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ded814c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   L2_cluster_id                         L2_cluster_label  \\\n",
      "0              0  Technical Problem-Solving Methodologies   \n",
      "1              1          Fictional Narrative Exploration   \n",
      "2              2                    AI Capability Testing   \n",
      "3              3     Technical Problem-Solving Assistance   \n",
      "4              4              Vocal Technique Comparisons   \n",
      "\n",
      "                              L2_cluster_description  \\\n",
      "0  This cluster represents systematic approaches ...   \n",
      "1  This cluster represents user-generated content...   \n",
      "2  This cluster represents comprehensive user int...   \n",
      "3  This cluster represents a comprehensive collec...   \n",
      "4  This cluster encompasses user inquiries that s...   \n",
      "\n",
      "                    L2_cluster_description_embedding  L2_cluster_trace_count  \n",
      "0  [-0.00941457785665989, -0.0065292189829051495,...                      54  \n",
      "1  [-0.01923833228647709, 0.01746535860002041, -0...                     193  \n",
      "2  [-0.00421322463080287, 0.01365547627210617, -0...                     537  \n",
      "3  [0.00796633493155241, 0.005814108066260815, -0...                     209  \n",
      "4  [-0.011478818021714687, -0.0010936849284917116...                       7  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upserting L2 clusters: 100%|██████████| 5/5 [00:00<00:00,  8.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully upserted L2 clusters.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## Processing L2 clusters (highest-level clusters extracted from the trace data). \n",
    "import ast\n",
    "from tqdm import tqdm\n",
    "\n",
    "# First, calculate trace counts for each L2 cluster\n",
    "unique_l2_clusters = (\n",
    "    df.groupby([\"L2_cluster_id\", \"L2_cluster_label\", \"L2_cluster_description\", \"L2_cluster_description_embedding\"])\n",
    "    .size()\n",
    "    .reset_index(name=\"L2_cluster_trace_count\")\n",
    ")\n",
    "\n",
    "# Printing the first few unique clusters.\n",
    "print(unique_l2_clusters.head())\n",
    "\n",
    "# Initializing L2 cluster metadata before upserting.\n",
    "for _, row in tqdm(unique_l2_clusters.iterrows(), total=len(unique_l2_clusters), desc=\"Upserting L2 clusters\"):\n",
    "    l2_cluster_metadata = {\n",
    "        \"type\": \"l2_cluster\",\n",
    "        \"name\": row[\"L2_cluster_label\"],\n",
    "        \"description\": row[\"L2_cluster_description\"],\n",
    "        \"trace_count\": row[\"L2_cluster_trace_count\"],\n",
    "    }\n",
    "    values = ast.literal_eval(row[\"L2_cluster_description_embedding\"])\n",
    "    vectors = [{\n",
    "        \"id\": str(row[\"L2_cluster_id\"]),\n",
    "        \"values\": values,\n",
    "        \"metadata\": l2_cluster_metadata,\n",
    "    }]\n",
    "    upsert_response = pc_index.upsert(vectors=vectors)\n",
    "    assert upsert_response[\"upserted_count\"] == 1 # Ensure that the upsert was successful.\n",
    "\n",
    "print(\"Successfully upserted L2 clusters.\") # If we've reached this point, then the L2 clusters have been upserted successfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7a85591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   L1_cluster_id                          L1_cluster_label  \\\n",
      "0              0  Methodological and Analytical Frameworks   \n",
      "1              1             AI Assistant Boundary Testing   \n",
      "2              2                   Broad Knowledge Testing   \n",
      "3              3              TrueNAS Storage Optimization   \n",
      "4              4     Game of Thrones speculative scenarios   \n",
      "\n",
      "                              L1_cluster_description  \\\n",
      "0  This cluster encompasses discussions centered ...   \n",
      "1  This cluster represents diverse user interacti...   \n",
      "2  This cluster represents user interactions that...   \n",
      "3  This cluster encompasses comprehensive discuss...   \n",
      "4  This cluster encompasses user-generated conten...   \n",
      "\n",
      "                    L1_cluster_description_embedding  L2_cluster_id  \\\n",
      "0  [-0.0216191615909338, 0.013525794260203838, -0...              0   \n",
      "1  [-0.008321586064994335, -0.0033742745872586966...              2   \n",
      "2  [-0.0021743522956967354, 0.019716961309313774,...              2   \n",
      "3  [-0.006666019558906555, 0.000851398624945432, ...              0   \n",
      "4  [-0.013002265244722366, 0.0060457391664385796,...              1   \n",
      "\n",
      "   L1_cluster_trace_count  \n",
      "0                      15  \n",
      "1                     134  \n",
      "2                     146  \n",
      "3                      16  \n",
      "4                      18  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upserting L1 clusters:   0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upsert response: {'upserted_count': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upserting L1 clusters:   8%|▊         | 2/25 [00:00<00:02,  9.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upsert response: {'upserted_count': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upserting L1 clusters:  16%|█▌        | 4/25 [00:00<00:02, 10.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upsert response: {'upserted_count': 1}\n",
      "Upsert response: {'upserted_count': 1}\n",
      "Upsert response: {'upserted_count': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upserting L1 clusters:  24%|██▍       | 6/25 [00:00<00:01, 10.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upsert response: {'upserted_count': 1}\n",
      "Upsert response: {'upserted_count': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upserting L1 clusters:  32%|███▏      | 8/25 [00:00<00:01, 11.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upsert response: {'upserted_count': 1}\n",
      "Upsert response: {'upserted_count': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upserting L1 clusters:  40%|████      | 10/25 [00:00<00:01,  9.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upsert response: {'upserted_count': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upserting L1 clusters:  48%|████▊     | 12/25 [00:01<00:01, 10.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upsert response: {'upserted_count': 1}\n",
      "Upsert response: {'upserted_count': 1}\n",
      "Upsert response: {'upserted_count': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upserting L1 clusters:  56%|█████▌    | 14/25 [00:01<00:01, 10.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upsert response: {'upserted_count': 1}\n",
      "Upsert response: {'upserted_count': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upserting L1 clusters:  64%|██████▍   | 16/25 [00:01<00:00, 11.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upsert response: {'upserted_count': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upserting L1 clusters:  72%|███████▏  | 18/25 [00:01<00:00, 11.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upsert response: {'upserted_count': 1}\n",
      "Upsert response: {'upserted_count': 1}\n",
      "Upsert response: {'upserted_count': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upserting L1 clusters:  80%|████████  | 20/25 [00:01<00:00, 11.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upsert response: {'upserted_count': 1}\n",
      "Upsert response: {'upserted_count': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upserting L1 clusters:  88%|████████▊ | 22/25 [00:02<00:00, 11.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upsert response: {'upserted_count': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upserting L1 clusters:  96%|█████████▌| 24/25 [00:02<00:00, 11.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upsert response: {'upserted_count': 1}\n",
      "Upsert response: {'upserted_count': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upserting L1 clusters: 100%|██████████| 25/25 [00:02<00:00, 10.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upsert response: {'upserted_count': 1}\n",
      "Successfully upserted L1 clusters.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Next, we need to upsert the L1 clusters (lower-level clusters than L2, but still pretty high).\n",
    "from tqdm import tqdm\n",
    "\n",
    "unique_l1_clusters = (\n",
    "    df.groupby([\"L1_cluster_id\", \"L1_cluster_label\", \"L1_cluster_description\", \"L1_cluster_description_embedding\", \"L2_cluster_id\"])\n",
    "    .size()\n",
    "    .reset_index(name=\"L1_cluster_trace_count\")\n",
    ")\n",
    "print(unique_l1_clusters.head())\n",
    "\n",
    "for _, row in tqdm(unique_l1_clusters.iterrows(), total=len(unique_l1_clusters), desc=\"Upserting L1 clusters\"):\n",
    "    l1_cluster_metadata = {\n",
    "        \"type\": \"l1_cluster\",\n",
    "        \"L2_cluster_id\": row[\"L2_cluster_id\"], # Need to store the L2 cluster ID for the L1 cluster, so that this can be returned in tool calls later on.\n",
    "        \"name\": row[\"L1_cluster_label\"],\n",
    "        \"description\": row[\"L1_cluster_description\"],\n",
    "        \"trace_count\": row[\"L1_cluster_trace_count\"],\n",
    "    }\n",
    "    values = ast.literal_eval(row[\"L1_cluster_description_embedding\"])\n",
    "    vectors = [{\n",
    "        \"id\": str(row[\"L1_cluster_id\"]),\n",
    "        \"values\": values,\n",
    "        \"metadata\": l1_cluster_metadata,\n",
    "    }]\n",
    "    upsert_response = pc_index.upsert(vectors=vectors)\n",
    "    print(f\"Upsert response: {upsert_response}\")\n",
    "    assert upsert_response[\"upserted_count\"] == 1 # Ensure that the upsert was successful.\n",
    "\n",
    "print(\"Successfully upserted L1 clusters.\") # If we've reached this point, then the L1 clusters have been upserted successfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1dcf8d31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   L0_cluster_id              L0_cluster_label  \\\n",
      "0              0  Programming Error Resolution   \n",
      "1              1     AI Assistant Interactions   \n",
      "2              2  Fictional Character Reunions   \n",
      "3              3  Diverse Information Requests   \n",
      "4              4  Diverse Information Requests   \n",
      "\n",
      "                              L0_cluster_description  \\\n",
      "0  This cluster represents a collection of progra...   \n",
      "1  This cluster represents diverse user interacti...   \n",
      "2  This cluster represents requests for creative ...   \n",
      "3  This cluster represents a wide range of user q...   \n",
      "4  This cluster represents a wide range of user q...   \n",
      "\n",
      "                    L0_cluster_description_embedding  L1_cluster_id  \\\n",
      "0  [-0.001186206005513668, 0.008096595294773579, ...             10   \n",
      "1  [-0.0019425011705607176, 0.006542277056723833,...              1   \n",
      "2  [-0.02054133079946041, 0.017430299893021584, -...              8   \n",
      "3  [-0.0035605276934802532, 0.011465399526059628,...              2   \n",
      "4  [0.00218771630898118, 0.020166805014014244, -0...              2   \n",
      "\n",
      "   L2_cluster_id  L0_cluster_trace_count  \n",
      "0              3                      25  \n",
      "1              2                      54  \n",
      "2              1                       9  \n",
      "3              2                      33  \n",
      "4              2                      44  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upserting L0 clusters:   2%|▏         | 1/50 [00:00<00:06,  7.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upsert response: {'upserted_count': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upserting L0 clusters:   6%|▌         | 3/50 [00:00<00:04, 10.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upsert response: {'upserted_count': 1}\n",
      "Upsert response: {'upserted_count': 1}\n",
      "Upsert response: {'upserted_count': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upserting L0 clusters:  10%|█         | 5/50 [00:00<00:04,  9.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upsert response: {'upserted_count': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upserting L0 clusters:  12%|█▏        | 6/50 [00:00<00:04,  8.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upsert response: {'upserted_count': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upserting L0 clusters:  16%|█▌        | 8/50 [00:00<00:04, 10.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upsert response: {'upserted_count': 1}\n",
      "Upsert response: {'upserted_count': 1}\n",
      "Upsert response: {'upserted_count': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upserting L0 clusters:  20%|██        | 10/50 [00:00<00:03, 10.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upsert response: {'upserted_count': 1}\n",
      "Upsert response: {'upserted_count': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upserting L0 clusters:  24%|██▍       | 12/50 [00:01<00:03, 11.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upsert response: {'upserted_count': 1}\n",
      "Upsert response: {'upserted_count': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upserting L0 clusters:  28%|██▊       | 14/50 [00:01<00:03, 10.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upsert response: {'upserted_count': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upserting L0 clusters:  32%|███▏      | 16/50 [00:01<00:03, 10.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upsert response: {'upserted_count': 1}\n",
      "Upsert response: {'upserted_count': 1}\n",
      "Upsert response: {'upserted_count': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upserting L0 clusters:  36%|███▌      | 18/50 [00:01<00:02, 10.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upsert response: {'upserted_count': 1}\n",
      "Upsert response: {'upserted_count': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upserting L0 clusters:  40%|████      | 20/50 [00:01<00:02, 11.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upsert response: {'upserted_count': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upserting L0 clusters:  44%|████▍     | 22/50 [00:02<00:02, 10.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upsert response: {'upserted_count': 1}\n",
      "Upsert response: {'upserted_count': 1}\n",
      "Upsert response: {'upserted_count': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upserting L0 clusters:  48%|████▊     | 24/50 [00:02<00:02, 10.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upsert response: {'upserted_count': 1}\n",
      "Upsert response: {'upserted_count': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upserting L0 clusters:  56%|█████▌    | 28/50 [00:02<00:02, 10.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upsert response: {'upserted_count': 1}\n",
      "Upsert response: {'upserted_count': 1}\n",
      "Upsert response: {'upserted_count': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upserting L0 clusters:  60%|██████    | 30/50 [00:02<00:02,  9.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upsert response: {'upserted_count': 1}\n",
      "Upsert response: {'upserted_count': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upserting L0 clusters:  64%|██████▍   | 32/50 [00:03<00:01,  9.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upsert response: {'upserted_count': 1}\n",
      "Upsert response: {'upserted_count': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upserting L0 clusters:  68%|██████▊   | 34/50 [00:03<00:01,  9.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upsert response: {'upserted_count': 1}\n",
      "Upsert response: {'upserted_count': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upserting L0 clusters:  72%|███████▏  | 36/50 [00:03<00:01,  7.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upsert response: {'upserted_count': 1}\n",
      "Upsert response: {'upserted_count': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upserting L0 clusters:  76%|███████▌  | 38/50 [00:03<00:01,  9.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upsert response: {'upserted_count': 1}\n",
      "Upsert response: {'upserted_count': 1}\n",
      "Upsert response: {'upserted_count': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upserting L0 clusters:  82%|████████▏ | 41/50 [00:04<00:00,  9.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upsert response: {'upserted_count': 1}\n",
      "Upsert response: {'upserted_count': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upserting L0 clusters:  88%|████████▊ | 44/50 [00:04<00:00,  9.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upsert response: {'upserted_count': 1}\n",
      "Upsert response: {'upserted_count': 1}\n",
      "Upsert response: {'upserted_count': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upserting L0 clusters:  92%|█████████▏| 46/50 [00:04<00:00, 10.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upsert response: {'upserted_count': 1}\n",
      "Upsert response: {'upserted_count': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upserting L0 clusters:  96%|█████████▌| 48/50 [00:04<00:00, 10.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upsert response: {'upserted_count': 1}\n",
      "Upsert response: {'upserted_count': 1}\n",
      "Upsert response: {'upserted_count': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upserting L0 clusters: 100%|██████████| 50/50 [00:04<00:00, 10.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upsert response: {'upserted_count': 1}\n",
      "Successfully upserted L0 clusters.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Next, we need to upsert the L0 clusters (lowest-level clusters, which are a level above the topics/trace descriptions).\n",
    "from tqdm import tqdm\n",
    "\n",
    "unique_l0_clusters = (\n",
    "    df.groupby([\"L0_cluster_id\", \"L0_cluster_label\", \"L0_cluster_description\", \"L0_cluster_description_embedding\", \"L1_cluster_id\", \"L2_cluster_id\"])\n",
    "    .size()\n",
    "    .reset_index(name=\"L0_cluster_trace_count\")\n",
    ")\n",
    "print(unique_l0_clusters.head())\n",
    "\n",
    "for _, row in tqdm(unique_l0_clusters.iterrows(), total=len(unique_l0_clusters), desc=\"Upserting L0 clusters\"):\n",
    "    l0_cluster_metadata = {\n",
    "        \"type\": \"l0_cluster\",\n",
    "        \"L1_cluster_id\": row[\"L1_cluster_id\"], # Need to store the L1 cluster ID for the L0 cluster, so that this can be returned in tool calls later on.\n",
    "        \"L2_cluster_id\": row[\"L2_cluster_id\"], # Need to store the L2 cluster ID for the L0 cluster, so that this can be returned in tool calls later on.\n",
    "        \"name\": row[\"L0_cluster_label\"],\n",
    "        \"description\": row[\"L0_cluster_description\"],\n",
    "        \"trace_count\": row[\"L0_cluster_trace_count\"],\n",
    "    }\n",
    "    values = ast.literal_eval(row[\"L0_cluster_description_embedding\"])\n",
    "    vectors = [{\n",
    "        \"id\": str(row[\"L0_cluster_id\"]),\n",
    "        \"values\": values,\n",
    "        \"metadata\": l0_cluster_metadata,\n",
    "    }]\n",
    "    upsert_response = pc_index.upsert(vectors=vectors) \n",
    "    print(f\"Upsert response: {upsert_response}\")\n",
    "    assert upsert_response[\"upserted_count\"] == 1 # Ensure that the upsert was successful.\n",
    "\n",
    "print(\"Successfully upserted L0 clusters.\") # If we've reached this point, then the L0 clusters have been upserted successfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "020c493a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Topic\n",
      "0  The user requested a personalized reality-shif...\n",
      "1  The user asked about the highest risk factor f...\n",
      "2  The user asked for a personalized reality-shif...\n",
      "3  The user asked for help choosing a reality-shi...\n",
      "4  The user asked the assistant to write terms an...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upserting topics: 100%|██████████| 995/995 [01:35<00:00, 10.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully upserted topics.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "def chunk_text(text: str, max_bytes: int = 20000) -> list[str]:\n",
    "    \"\"\"Split text into chunks that don't exceed max_bytes when encoded as UTF-8.\"\"\"\n",
    "    text_bytes = text.encode('utf-8')\n",
    "    if len(text_bytes) <= max_bytes:\n",
    "        return [text]\n",
    "    \n",
    "    chunks = []\n",
    "    for i in range(0, len(text_bytes), max_bytes):\n",
    "        chunk_bytes = text_bytes[i:i+max_bytes]\n",
    "        chunks.append(chunk_bytes.decode('utf-8', errors='ignore'))\n",
    "    \n",
    "    return chunks\n",
    "\n",
    "unique_topics = df.drop_duplicates(subset=[\"Topic\"]).reset_index(drop=True)\n",
    "print(unique_topics[[\"Topic\"]].head())\n",
    "\n",
    "for i, row in tqdm(unique_topics.iterrows(), total=len(unique_topics), desc=\"Upserting topics\"):\n",
    "    # Base metadata without description\n",
    "    base_metadata = {\n",
    "        \"type\": \"topic\",\n",
    "        \"trace\": row[\"Conversation\"],\n",
    "        \"L0_cluster_id\": row[\"L0_cluster_id\"],\n",
    "        \"L1_cluster_id\": row[\"L1_cluster_id\"],\n",
    "        \"L2_cluster_id\": row[\"L2_cluster_id\"],\n",
    "        \"model\": row[\"Model\"],\n",
    "        \"toxic\": row[\"Toxic\"],\n",
    "        \"state\": row[\"State\"],\n",
    "        \"country\": row[\"Country\"],\n",
    "        \"hour\": row[\"Hour of Day\"],\n",
    "    }\n",
    "    \n",
    "    # Calculate base metadata size (without description)\n",
    "    base_metadata_bytes = len(json.dumps(base_metadata).encode('utf-8'))\n",
    "    \n",
    "    # Determine how much space we have for description (leave some buffer). 20KB is the maximum that we want to store in one chunk on Pinecone.\n",
    "    max_description_bytes = 20000 - base_metadata_bytes - 100  # 100 byte buffer\n",
    "    \n",
    "    # Split description into chunks\n",
    "    description_chunks = chunk_text(row[\"Topic\"], max_description_bytes)\n",
    "    \n",
    "    # Get the embedding (same for all chunks of the same topic)\n",
    "    values = ast.literal_eval(row[\"Topic_Embedding\"])\n",
    "\n",
    "    # Upsert each chunk\n",
    "    for chunk_idx, chunk in enumerate(description_chunks):\n",
    "        chunk_metadata = base_metadata.copy()\n",
    "        chunk_metadata[\"description\"] = chunk\n",
    "        \n",
    "        vectors = [{\n",
    "            \"id\": f\"topic_{i}_{chunk_idx}\",\n",
    "            \"values\": values,  # Same embedding for all chunks\n",
    "            \"metadata\": chunk_metadata,\n",
    "        }]\n",
    "        \n",
    "        upsert_response = pc_index.upsert(vectors=vectors)\n",
    "        assert upsert_response[\"upserted_count\"] == 1\n",
    "\n",
    "print(\"Successfully upserted topics.\") # If we've reached this point, then the topics have been upserted successfully."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
