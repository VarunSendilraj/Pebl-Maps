{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f507d4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install datasets\n",
    "%pip install transformers\n",
    "%pip install huggingface_hub\n",
    "%pip install matplotlib seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbd539f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Streaming mode for large datasets\n",
    "# This loads data on-demand without downloading everything first\n",
    "\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "# Streaming mode - data is loaded on-demand, not all at once\n",
    "ds_streaming = load_dataset(\"allenai/WildChat-1M\", split=\"train\", streaming=True)\n",
    "\n",
    "# Take only the first 1k English-language records for exploration (more memory efficient)\n",
    "ds_english_stream = ds_streaming.filter(lambda row: row['language'] == 'English')\n",
    "\n",
    "# We'll collect up to (for example) 2000 records, then dedup, and take the first 1000 unique\n",
    "max_to_scan = 3000  # oversample to ensure uniqueness amongst 1k rows\n",
    "ds_candidates = [item for item in tqdm(ds_english_stream.take(max_to_scan), total=max_to_scan, desc=f\"Scanning {max_to_scan} English samples\")]\n",
    "\n",
    "ds_df = pd.DataFrame(ds_candidates)\n",
    "num_duplicates = ds_df.duplicated(subset=['conversation']).sum()\n",
    "\n",
    "# Drop duplicate 'conversation' rows; keep first occurrence\n",
    "ds_unique = ds_df.drop_duplicates(subset=['conversation'], keep='first').head(1000)\n",
    "\n",
    "# Convert back to list-of-dicts for further use\n",
    "ds = ds_unique.to_dict(orient='records')\n",
    "\n",
    "print(\"All rows have 'language' = 'English':\", (pd.Series([row['language'] for row in ds]) == \"English\").all())\n",
    "print(f\"Number of duplicate 'conversation' rows removed in scan: {num_duplicates}\")\n",
    "print(f\"Size of deduplicated ds: {len(ds)}\")\n",
    "if len(ds) < 1000:\n",
    "    print(\"Warning: Less than 1000 unique conversations found in scanned set!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8525616b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "\n",
    "# Set plotting style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (15, 10)\n",
    "\n",
    "# Convert the list of dicts to a DataFrame\n",
    "df = pd.DataFrame(ds)\n",
    "\n",
    "# Show all columns (no truncation)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Print the DataFrame columns\n",
    "print(\"Columns in the dataset:\")\n",
    "print(df.columns.tolist())\n",
    "print(f\"\\nTotal records: {len(df)}\")\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb26e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "# Preprocess data for analysis\n",
    "# Extract hour of day from timestamp\n",
    "# Since timestamp is already a pandas Timestamp, we can use .dt.hour directly\n",
    "\n",
    "# Convert timestamp to datetime if it's not already (should already be Timestamp)\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "\n",
    "# Extract hour using .dt.hour accessor (vectorized, much faster than apply)\n",
    "df['hour_of_day'] = df['timestamp'].dt.hour\n",
    "\n",
    "# Logging content and role for every turn in the conversation.\n",
    "convs = []\n",
    "for idx, conv in enumerate(df['conversation']):\n",
    "    trace_dict = defaultdict(dict)\n",
    "    for turn in conv:\n",
    "        # trace_dict[turn_identifier] has 2 keys: role_user and role_assistant\n",
    "        trace_dict[turn['turn_identifier']][turn['role']] = turn['content']\n",
    "    convs.append(trace_dict)\n",
    "\n",
    "df['conversation'] = convs\n",
    "# Logging the first conversation.\n",
    "print(f\"First conversation: {df['conversation'].iloc[0]}\")\n",
    "\n",
    "# Check for missing values\n",
    "print(\"Missing values per column:\")\n",
    "print(df[['model', 'turn', 'hour_of_day', 'state', 'country']].isnull().sum())\n",
    "print(f\"\\nTotal records: {len(df)}\")\n",
    "print(f\"Records with all required fields: {df[['model', 'turn', 'hour_of_day', 'state', 'country']].notna().all(axis=1).sum()}\")\n",
    "unique_hours = df['hour_of_day'].nunique(dropna=True)\n",
    "print(f\"\\nNumber of unique 'hour_of_day' values: {unique_hours}\")\n",
    "print(f\"Unique values: {sorted(df['hour_of_day'].dropna().unique())}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d37b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create distribution visualizations for each facet\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "fig.suptitle('Distribution Analysis Across Facets', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 1. Model distribution\n",
    "ax1 = axes[0, 0]\n",
    "model_counts = df['model'].value_counts()\n",
    "if len(model_counts) > 20:\n",
    "    # Show top 20 if too many models\n",
    "    model_counts = model_counts.head(20)\n",
    "    ax1.barh(range(len(model_counts)), model_counts.values)\n",
    "    ax1.set_yticks(range(len(model_counts)))\n",
    "    ax1.set_yticklabels(model_counts.index)\n",
    "    ax1.set_xlabel('Count')\n",
    "    ax1.set_title(f'Model Distribution (Top 20)')\n",
    "else:\n",
    "    ax1.barh(range(len(model_counts)), model_counts.values)\n",
    "    ax1.set_yticks(range(len(model_counts)))\n",
    "    ax1.set_yticklabels(model_counts.index)\n",
    "    ax1.set_xlabel('Count')\n",
    "    ax1.set_title('Model Distribution')\n",
    "ax1.invert_yaxis()\n",
    "\n",
    "# 2. Turn (#turns) distribution\n",
    "ax2 = axes[0, 1]\n",
    "turn_counts = df['turn'].value_counts().sort_index()\n",
    "ax2.bar(turn_counts.index, turn_counts.values, edgecolor='black', alpha=0.7)\n",
    "ax2.set_xlabel('Number of Turns')\n",
    "ax2.set_ylabel('Count')\n",
    "ax2.set_title('Turn Distribution')\n",
    "ax2.set_xticks(range(0, int(turn_counts.index.max()) + 1, max(1, int(turn_counts.index.max()) // 10)))\n",
    "\n",
    "# 3. Time of day (hour) distribution\n",
    "ax3 = axes[0, 2]\n",
    "hour_counts = df['hour_of_day'].dropna().value_counts().sort_index()\n",
    "ax3.bar(hour_counts.index, hour_counts.values, edgecolor='black', alpha=0.7, color='skyblue')\n",
    "ax3.set_xlabel('Hour of Day')\n",
    "ax3.set_ylabel('Count')\n",
    "ax3.set_title('Timestamp Distribution (Hour of Day)')\n",
    "ax3.set_xticks(range(0, 24, 2))\n",
    "ax3.set_xlim(-0.5, 23.5)\n",
    "\n",
    "# 4. State distribution\n",
    "ax4 = axes[1, 0]\n",
    "state_counts = df['state'].dropna().value_counts()\n",
    "if len(state_counts) > 15:\n",
    "    # Show top 15 if too many states\n",
    "    state_counts = state_counts.head(15)\n",
    "    ax4.barh(range(len(state_counts)), state_counts.values)\n",
    "    ax4.set_yticks(range(len(state_counts)))\n",
    "    ax4.set_yticklabels(state_counts.index)\n",
    "    ax4.set_xlabel('Count')\n",
    "    ax4.set_title(f'State Distribution (Top 15)')\n",
    "else:\n",
    "    ax4.barh(range(len(state_counts)), state_counts.values)\n",
    "    ax4.set_yticks(range(len(state_counts)))\n",
    "    ax4.set_yticklabels(state_counts.index)\n",
    "    ax4.set_xlabel('Count')\n",
    "    ax4.set_title('State Distribution')\n",
    "ax4.invert_yaxis()\n",
    "\n",
    "# 5. Country distribution\n",
    "ax5 = axes[1, 1]\n",
    "country_counts = df['country'].dropna().value_counts()\n",
    "if len(country_counts) > 15:\n",
    "    # Show top 15 if too many countries\n",
    "    country_counts = country_counts.head(15)\n",
    "    ax5.barh(range(len(country_counts)), country_counts.values)\n",
    "    ax5.set_yticks(range(len(country_counts)))\n",
    "    ax5.set_yticklabels(country_counts.index)\n",
    "    ax5.set_xlabel('Count')\n",
    "    ax5.set_title(f'Country Distribution (Top 15)')\n",
    "else:\n",
    "    ax5.barh(range(len(country_counts)), country_counts.values)\n",
    "    ax5.set_yticks(range(len(country_counts)))\n",
    "    ax5.set_yticklabels(country_counts.index)\n",
    "    ax5.set_xlabel('Count')\n",
    "    ax5.set_title('Country Distribution')\n",
    "ax5.invert_yaxis()\n",
    "\n",
    "# 6. Summary statistics\n",
    "ax6 = axes[1, 2]\n",
    "ax6.axis('off')\n",
    "summary_text = f\"\"\"\n",
    "Summary Statistics:\n",
    "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n",
    "\n",
    "Total Records: {len(df):,}\n",
    "\n",
    "Model: {df['model'].nunique()} unique models\n",
    "Turn: {df['turn'].min():.0f} - {df['turn'].max():.0f} (mean: {df['turn'].mean():.1f})\n",
    "Hour: {df['hour_of_day'].min():.0f}:00 - {df['hour_of_day'].max():.0f}:00\n",
    "State: {df['state'].nunique()} unique states\n",
    "Country: {df['country'].nunique()} unique countries\n",
    "\n",
    "Missing Values:\n",
    "  - Model: {df['model'].isnull().sum()}\n",
    "  - Turn: {df['turn'].isnull().sum()}\n",
    "  - Hour: {df['hour_of_day'].isnull().sum()}\n",
    "  - State: {df['state'].isnull().sum()}\n",
    "  - Country: {df['country'].isnull().sum()}\n",
    "\"\"\"\n",
    "ax6.text(0.1, 0.5, summary_text, fontsize=11, family='monospace',\n",
    "         verticalalignment='center', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print top values for each facet\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TOP VALUES FOR EACH FACET\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nüìä Top 10 Models:\")\n",
    "print(df['model'].value_counts().head(10))\n",
    "print(\"\\nüìä Top 10 Turn Values:\")\n",
    "print(df['turn'].value_counts().head(10))\n",
    "print(\"\\nüìä Hour Distribution (Top 10):\")\n",
    "print(df['hour_of_day'].value_counts().head(10))\n",
    "print(\"\\nüìä Top 10 States:\")\n",
    "print(df['state'].value_counts().head(10))\n",
    "print(\"\\nüìä Top 10 Countries:\")\n",
    "print(df['country'].value_counts().head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b3cc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f11cb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new dataframe with the specified columns and standardized column names\n",
    "selected_columns = {\n",
    "    'model': 'Model',\n",
    "    'conversation': 'Conversation',\n",
    "    'language': 'Language',\n",
    "    'toxic': 'Toxic',\n",
    "    'state': 'State',\n",
    "    'country': 'Country',\n",
    "    'hour_of_day': 'Hour of Day'\n",
    "}\n",
    "df_selected = df[list(selected_columns.keys())].rename(columns=selected_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584d3aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new column for the LLM-generated topic/facet and its embedding\n",
    "df_selected['Topic'] = ''\n",
    "df_selected['Topic_Embedding'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6d3bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_selected.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8ebbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_selected.to_csv('selected_conversations.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
